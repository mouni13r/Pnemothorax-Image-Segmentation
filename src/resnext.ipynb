{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnext.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTxa-5Hgxkym"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77S8qumS3Zir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbace79-c32f-43a8-9dff-ad88cd674dc6"
      },
      "source": [
        "!pip3 install kymatio\n",
        "!pip3 install scikit-cuda\n",
        "!pip uninstall --y torchvision\n",
        "!pip install torch==1.7.0 torchvision==0.8.0\n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations_experimental"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kymatio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/ae/88e1a04fe72c71c703cd9230691e4bcc6ea1300f187cfc729ddec8b31bcf/kymatio-0.2.0-py3-none-any.whl (92kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 40kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 4.1MB/s \n",
            "\u001b[?25hCollecting configparser\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kymatio) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kymatio) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kymatio) (2.4.7)\n",
            "Installing collected packages: configparser, kymatio\n",
            "Successfully installed configparser-5.0.2 kymatio-0.2.0\n",
            "Collecting scikit-cuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/8b/36d178c3b98524fe5b1cc15d075d34e2e6e291c4b0461f6e901f1e0bc736/scikit_cuda-0.5.3-py2.py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 5.7MB/s \n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[?25hUninstalling torchvision-0.9.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Collecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |███████████▍                    | 275.4MB 1.6MB/s eta 0:05:22\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[?25hCollecting git+https://github.com/albumentations-team/albumentations_experimental\n",
            "  Cloning https://github.com/albumentations-team/albumentations_experimental to /tmp/pip-req-build-nv8bexez\n",
            "  Running command git clone -q https://github.com/albumentations-team/albumentations_experimental /tmp/pip-req-build-nv8bexez\n",
            "Requirement already satisfied, skipping upgrade: albumentations in /usr/local/lib/python3.7/dist-packages (from albumentations-experimental==0.0.1) (0.1.12)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations->albumentations-experimental==0.0.1) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations->albumentations-experimental==0.0.1) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations->albumentations-experimental==0.0.1) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (0.10.0)\n",
            "Building wheels for collected packages: albumentations-experimental, imgaug\n",
            "  Building wheel for albumentations-experimental (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations-experimental: filename=albumentations_experimental-0.0.1-cp37-none-any.whl size=5972 sha256=b9eb69c261b8c618cfc6c3677e0984720fc47dd70cac50a02b4fa023ee67281e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nkf9oycy/wheels/a0/58/eb/8abea5cf33c9870c9317f9bf175bccde07b2b486f069c512a1\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp37-none-any.whl size=654019 sha256=7c36ad945ba20254cdd690ea8ca3db9a9e8d0bf4d4e47db9c3a0d797acdb5ee4\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations-experimental imgaug\n",
            "Installing collected packages: albumentations-experimental, imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed albumentations-experimental-0.0.1 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piMfHYKcjqDP"
      },
      "source": [
        "import numpy as np \n",
        "import os,csv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "import albumentations as A\n",
        "import random\n",
        "from torchvision import transforms\n",
        "import torch.optim\n",
        "from PIL import Image\n",
        "#from kymatio.torch import Scattering2D\n",
        "import pickle\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b97ExyiSjzQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4ea5fa-d7c4-4dfa-fb11-d0eb42e834e8"
      },
      "source": [
        "import csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True )\n",
        "# 4/1AY0e-g4UbHq_CkCkQLG7ug0yUnXepWmT7pS_gsiVPgrnh2-PU7RKqA7JzTk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNq5E9VNkGOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543a8e41-5ea0-4960-9259-404f40d83fb8"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFhefgG8km2N"
      },
      "source": [
        "NUM_EPOCHS = 25\n",
        "BATCH_SIZE = 4\n",
        "LEARNING_RATE = 1e-3"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEM8b_3Kkqmj"
      },
      "source": [
        "def getImageName(filename):\n",
        "    imageName = filename[:-4] + '_Annotation.png'\n",
        "    return imageName"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deQgTq8xqWKU"
      },
      "source": [
        "class diceloss(torch.nn.Module):\n",
        "    def init(self):\n",
        "        super(diceLoss, self).init()\n",
        "    def forward(self, target, pred):\n",
        "       smooth = 1.\n",
        "       iflat = pred.contiguous().view(-1)\n",
        "       tflat = target.contiguous().view(-1)\n",
        "       intersection = (iflat * tflat).sum()\n",
        "       A_sum = torch.sum(iflat * iflat)\n",
        "       B_sum = torch.sum(tflat * tflat)\n",
        "       return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQoOBCzqWKY"
      },
      "source": [
        "def iou_binary(out, labels, EMPTY=1., ignore=None, per_image=True, threshold=0.5):\n",
        "    \"\"\"\n",
        "    IoU for foreground class\n",
        "    binary: 1 foreground, 0 background\n",
        "    \"\"\"\n",
        "    out = torch.sigmoid(out)\n",
        "    preds = (out.data > threshold).long()\n",
        "    if not per_image:\n",
        "        preds, labels = (preds,), (labels,)\n",
        "    ious = []\n",
        "    for pred, label in zip(preds, labels):\n",
        "        intersection = ((label == 1) & (pred == 1)).sum()\n",
        "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
        "        if not union:\n",
        "            iou = EMPTY\n",
        "        else:\n",
        "            iou = float(intersection) / float(union)\n",
        "        ious.append(iou)\n",
        "    iou = np.mean(np.array(ious))    # mean accross images if per_image\n",
        "    return 100 * iou"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr29aVozqWKN"
      },
      "source": [
        "from PIL import ImageFilter\n",
        "preprocessing = 0\n",
        "class HeadDataset(Dataset):\n",
        "\n",
        "    def __init__(self, image_path, mask_path, files, transform=None):\n",
        "        self.image_path = image_path\n",
        "        self.mask_path = mask_path\n",
        "        self.files = files\n",
        "        self.transform = transform\n",
        "        self.aug = A.Compose([\n",
        "                A.CLAHE(clip_limit=5.0, tile_grid_size=(8, 8), always_apply=False, p=0.5) ,\n",
        "                A.Blur(blur_limit=3)\n",
        "            ])\n",
        "\n",
        "\n",
        "    def __len__(self) :\n",
        "        return len(self.files)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.image_path,self.files[idx])\n",
        "        mask_name = os.path.join(self.mask_path,getImageName(self.files[idx]))\n",
        "        \n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        mask = Image.open(mask_name).convert('L')\n",
        "\n",
        "        #print(type(image))\n",
        "        image = self.aug(image=np.array(image))['image']\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.convert('L')\n",
        "\n",
        "        #print(\"yes\")\n",
        "\n",
        "        if self.transform :\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "        #print(type(image))\n",
        "        #print(\"yes\")\n",
        "        #image = self.aug(image=np.array(image))['image']\n",
        "        \n",
        "        image = image.to(device=device)\n",
        "        mask = mask.to(device=device)\n",
        "        \n",
        "        sample = {'image': image, 'mask': mask}\n",
        "        return sample\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJMHKXWkqWKP"
      },
      "source": [
        "base_folder = '/content/drive/MyDrive/cv/DUNET-HC-18_Data/DUNET/hc18/training_set/training_set'\n",
        "image_folder = base_folder\n",
        "mask_folder = base_folder"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfxouiVQqWKR"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((544, 800)),\n",
        "    transforms.ToTensor()\n",
        "    #transforms.Normalize((0.485), (0.229))\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfIeftofqWKT"
      },
      "source": [
        "with open('/content/drive/MyDrive/cv/manaswini/HC-18/train.pkl', 'rb') as fid:\n",
        "    train = pickle.load(fid)\n",
        "with open('/content/drive/MyDrive/cv/manaswini/HC-18/val.pkl', 'rb') as fid:\n",
        "    val = pickle.load(fid)\n",
        "    \n",
        "Head_Train_Dataset = HeadDataset(image_folder,mask_folder,train,transform)\n",
        "trainLoader = DataLoader(Head_Train_Dataset, batch_size=BATCH_SIZE,shuffle=True)\n",
        "\n",
        "Val_Dataset = HeadDataset(image_folder,mask_folder,val,transform)\n",
        "valLoader = DataLoader(Val_Dataset, batch_size=BATCH_SIZE,shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17E6j5hBqWKU"
      },
      "source": [
        "!pip install git+https://github.com/qubvel/segmentation_models.pytorch > /dev/null 2>&1 # Install segmentations_models.pytorch, with no bash output."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewdOe9ZQqWKU"
      },
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "model = smp.Unet(\"resnext50_32x4d\", encoder_weights=\"imagenet\", in_channels=1, classes=1, activation = 'sigmoid').to(device)\n",
        "\n",
        "criterion = diceloss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=LEARNING_RATE*0.1)\n",
        "# optimizer = torch.optim.RMSprop(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-8, momentum=0.9)\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSDgkmr3w6kH"
      },
      "source": [
        "iou_score_train = []\n",
        "dice_loss_train = []\n",
        "iou_score_val= []\n",
        "dice_loss_val = []\n",
        "best_iou_score = -np.inf"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWupfqW5qWKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bcd04a-c04d-4218-eec4-41c3c5eea44d"
      },
      "source": [
        "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    ##training\n",
        "    model.train()\n",
        "    for i, data in tqdm( enumerate(trainLoader,0), total=int(len(Head_Train_Dataset)/trainLoader.batch_size)):\n",
        "        iou = []\n",
        "        loss_arr = []\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        images = data['image']\n",
        "        masks = data['mask']\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        #print(\"Training: Mini - Batch \",i,\"Loss\", loss.item())\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "            iou.append(iou_binary(outputs, masks, per_image=True, threshold=0.59))\n",
        "            loss_arr.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    iou_score_train.append(np.mean(iou))\n",
        "    dice_loss_train.append(np.mean(loss_arr))\n",
        "\n",
        "    ##evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        iou = []\n",
        "        loss_arr = []\n",
        "        for k, data in tqdm(enumerate(valLoader,0), total=int(len(Val_Dataset)/valLoader.batch_size)):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            images = data['image'].to(device)\n",
        "            masks = data['mask'].to(device)\n",
        "            # scatters = data['scatter']\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            #print(\"Validation: Mini - Batch \",k,\"Loss\", loss.item())\n",
        "\n",
        "            outputs = model(images)\n",
        "            iou.append(iou_binary(outputs, masks, per_image=True, threshold=0.59))\n",
        "            loss_arr.append(loss.item())\n",
        "   \n",
        "    iou_score_val.append(np.mean(iou))\n",
        "    dice_loss_val.append(np.mean(loss_arr))\n",
        "\n",
        "    with open('/content/drive/MyDrive/cv/manaswini/HC-18/resnext-sig/epoch_iousAndArrays.pkl', 'wb') as fid:\n",
        "        pickle.dump({'iou_score_train':iou_score_train, 'dice_loss_train': dice_loss_train, 'iou_score_val':iou_score_val, 'dice_loss_val':dice_loss_val}, fid)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(\"Epoch [{}]: Train - loss:{}, iou:{}; Val - loss:{}, iou:{}\".format(epoch, dice_loss_train[-1],iou_score_train[-1], dice_loss_val[-1],iou_score_val[-1]))\n",
        "        running_loss = 0.0\n",
        "    \n",
        "\n",
        "    if iou_score_val[-1]>best_iou_score:\n",
        "        best_iou_score = iou_score_val[-1]\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/cv/manaswini/HC-18/resnext-sig/best-model\")\n",
        "        with open('/content/drive/MyDrive/cv/manaswini/HC-18/resnext-sig/best_iou.pkl', 'wb') as fid:\n",
        "            pickle.dump(best_iou_score, fid)\n",
        "        \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200it [11:38,  3.49s/it]\n",
            "  2%|▏         | 1/50 [00:03<03:05,  3.79s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAUMQo7TqWKa"
      },
      "source": [
        "print(best_iou_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrZ8dUH1vWHS"
      },
      "source": [
        "def plot(scores, name):\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.plot(range(len(scores)), scores, label=f'train {name}',marker=\".\")\n",
        "    #plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n",
        "    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n",
        "    plt.legend(); \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXXkIB1OqWKa"
      },
      "source": [
        "with open('/content/drive/MyDrive/cv/manaswini/HC-18/resnext-sig/epoch_iousAndArrays.pkl', 'rb') as fid:\n",
        "    data = pickle.load(fid)\n",
        "    iou_score_train_cla = data['iou_score_train']\n",
        "    dice_loss_train_cla = data['dice_loss_train']\n",
        "    iou_score_val_cla = data['iou_score_val']\n",
        "    dice_loss_val_cla = data['dice_loss_val']\n",
        "    print(dice_loss_val_cla[np.argmax(iou_score_val_cla)])\n",
        "    print(np.max(iou_score_val_cla))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A519b_j9t7qe"
      },
      "source": [
        "with open('/content/drive/MyDrive/cv/manaswini/HC-18/smp-preproc/epoch_iousAndArrays.pkl', 'rb') as fid:\n",
        "    data = pickle.load(fid)\n",
        "    iou_score_train_pre = data['iou_score_train']\n",
        "    dice_loss_train_pre = data['dice_loss_train']\n",
        "    iou_score_val_pre = data['iou_score_val']\n",
        "    dice_loss_val_pre = data['dice_loss_val']\n",
        "    print(dice_loss_val[np.argmax(iou_score_val)])\n",
        "    print(np.max(iou_score_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cx_n0pXqWKc"
      },
      "source": [
        "#25epochs-test_train split\n",
        "epoch_train_losses = dice_loss_train_pre\n",
        "epoch_train_iou = iou_score_train_pre\n",
        "epoch_val_losses = dice_loss_val_pre\n",
        "epoch_val_iou = iou_score_val_pre\n",
        "plot(epoch_train_losses, \"Training loss preproc\")\n",
        "plot(epoch_train_iou, \"Training-iou score preproc\")\n",
        "plot(epoch_val_losses, \"Test loss preproc\")\n",
        "plot(epoch_val_iou, \"Test-iou score preproc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXT3zbJlwA-K"
      },
      "source": [
        "epoch_train_losses = dice_loss_train_cla\n",
        "epoch_train_iou = iou_score_train_cla\n",
        "epoch_val_losses = dice_loss_val_cla\n",
        "epoch_val_iou = iou_score_val_cla\n",
        "plot(epoch_train_losses, \"Training loss CLAHE\")\n",
        "plot(epoch_train_iou, \"Training-iou score CLAHE\")\n",
        "plot(epoch_val_losses, \"Test loss CLAHE\")\n",
        "plot(epoch_val_iou, \"Test-iou score CLAHE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnx-5x0wL7U"
      },
      "source": [
        "def plot_2(score1,score2,xlabel,title_name,leg1,leg2):\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.plot(range(len(score1)), score1,marker=\".\")\n",
        "    plt.plot(range(len(score2)), score2,marker = \".\")\n",
        "    #plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n",
        "    plt.title(title_name);\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.legend([leg1,leg2]); \n",
        "    plt.show()\n",
        "plot_2(dice_loss_train_cla,dice_loss_train_pre,\"Epoch\",\"Comparing preprocessing techniques\",\"CLAHE\",\"preproc\")    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZqzYJrBqWKc"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/cv/manaswini/HC-18/smp-clahe/best-model'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj8pfW9Yqdgu"
      },
      "source": [
        "blur=((3,3),1)\n",
        "erode_=(5,5)\n",
        "dilate_=(3, 3)\n",
        "#plt.imshow( mask , cv2.dilate(cv2.erode(cv2.GaussianBlur(mask/255, blur[0], blur[1]), np.ones(erode_)), np.ones(dilate_))*255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoWd_hwgqWKd"
      },
      "source": [
        "# evaluate model:\n",
        "model.eval()\n",
        "iou = []\n",
        "with torch.no_grad():\n",
        "    for k, data in enumerate(valLoader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        images = data['image'].to(device)\n",
        "        masks = data['mask'].to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        iou.append(iou_binary(outputs, masks, per_image=True, threshold=0.59))\n",
        "        for i in range(images.shape[0]):\n",
        "            f, ax = plt.subplots(1,4,figsize=(10,10))\n",
        "            \n",
        "            ax[0].axis('off')\n",
        "            ax[0].set_title('Original image')\n",
        "            ax[1].axis('off')\n",
        "            ax[1].set_title('Target mask')\n",
        "            ax[2].axis('off')\n",
        "            ax[2].set_title('Predicted mask')\n",
        "            ax[3].axis('off')\n",
        "            ax[3].set_title('Eroded and Dilated')\n",
        "            image = transforms.ToPILImage()(images[i])\n",
        "            ax[0].imshow(image,cmap='gray')\n",
        "            mask = transforms.ToPILImage()(masks[i])\n",
        "\n",
        "            ax[1].imshow(mask,cmap='gray')\n",
        "            output = torch.sigmoid(outputs[i])\n",
        "            output = (output.data > 0.59).long()\n",
        "            # print(output)\n",
        "            # output = transforms.ToPILImage()(output)\n",
        "            output = torch.squeeze(output, 0)\n",
        "            #kernel_e = np.ones((6, 6), np.uint8)\n",
        "            #kernel_d = np.ones((6, 6), np.uint8)\n",
        "            mask2 = cv2.dilate(cv2.erode(cv2.GaussianBlur(np.array(output.cpu())/255, blur[0], blur[1]), np.ones(erode_)), np.ones(dilate_))*255\n",
        "            for i in range(15) :\n",
        "                mask2 = cv2.dilate(cv2.erode(mask2, np.ones(erode_)), np.ones(dilate_))\n",
        "            ax[2].imshow(output.cpu(),cmap='gray')\n",
        "            ax[3].imshow(mask2,cmap='gray')\n",
        "            plt.show()\n",
        "        break\n",
        "\n",
        "print('Finished Evaluation')\n",
        "# print('iou:',np.mean(iou))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0AxzKMotdzU"
      },
      "source": [
        "trans1 = transforms.ToTensor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CajORu_IodN7"
      },
      "source": [
        "# evaluate model:\n",
        "model.eval()\n",
        "iou = []\n",
        "with torch.no_grad():\n",
        "    for k, data in enumerate(trainLoader, 0):\n",
        "        images = data['image'].to(device)\n",
        "        masks = data['mask'].to(device)\n",
        "        outputs = model(images)\n",
        "        #print(masks.shape[0])        \n",
        "        iou.append(iou_binary(outputs, masks, per_image=True, threshold=0.59))\n",
        "\n",
        "print('Finished Evaluation')\n",
        "print('iou:',np.mean(iou))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}